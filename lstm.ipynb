{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "import keras.layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import L1L2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train, valid, test = pickle.load(open('dataset.pickle', 'rb'))\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['raw_acc','proc_gyro','raw_magnet','watch_acceleration','watch_heading', 'location', 'location_quick_features', 'audio_naive', 'audio_properties', 'discrete', 'lf_measurements']]\n",
    "y_train = train.iloc[:,-8:]\n",
    "x_test = test[['raw_acc','proc_gyro','raw_magnet','watch_acceleration','watch_heading', 'location', 'location_quick_features', 'audio_naive', 'audio_properties', 'discrete', 'lf_measurements']]\n",
    "y_test = np.asarray(test.iloc[:,-8:])\n",
    "y_test_decode = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_decode.insert(len(y_test_decode),np.argmax(y_test[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #scale features between 0 and 1\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = np.asarray(x_train).reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "x_test = np.asarray(x_test).reshape(x_test.shape[0], 1, x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(LSTM(500, input_shape=(x_train.shape[1], x_train.shape[2]), bias_regularizer=L1L2(l1=0.01, l2=0.01)))\n",
    "model.add(LSTM(500, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227768 samples, validate on 75923 samples\n",
      "Epoch 1/5\n",
      "227768/227768 [==============================] - 209s 919us/step - loss: 0.9966 - acc: 0.6385 - val_loss: 1.3015 - val_acc: 0.5320\n",
      "Epoch 2/5\n",
      "227768/227768 [==============================] - 206s 903us/step - loss: 0.7801 - acc: 0.7195 - val_loss: 1.4471 - val_acc: 0.5097\n",
      "Epoch 3/5\n",
      "227768/227768 [==============================] - 206s 905us/step - loss: 0.6878 - acc: 0.7530 - val_loss: 1.4621 - val_acc: 0.5064\n",
      "Epoch 4/5\n",
      "227768/227768 [==============================] - 207s 910us/step - loss: 0.6400 - acc: 0.7704 - val_loss: 1.5459 - val_acc: 0.5141\n",
      "Epoch 5/5\n",
      "227768/227768 [==============================] - 206s 905us/step - loss: 0.6029 - acc: 0.7843 - val_loss: 1.7544 - val_acc: 0.4960\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train], batch_size=20, y=y_train, verbose=1, validation_split=0.25, \n",
    "          shuffle=True, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277601796924495\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(x_test)\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "print(accuracy_score(y_test_decode, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34726\n",
      "26884\n"
     ]
    }
   ],
   "source": [
    "a= [0,1,1]\n",
    "print(len(y_test_decode))\n",
    "print(np.count_nonzero(y_test_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
