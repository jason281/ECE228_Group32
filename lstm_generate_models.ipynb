{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "import keras.layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = pickle.load(open('dataset.pickle', 'rb'))\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[['raw_acc','proc_gyro','raw_magnet','watch_acceleration','watch_heading', 'location', 'location_quick_features', 'audio_naive', 'audio_properties', 'discrete', 'lf_measurements']]\n",
    "y_train = train.iloc[:,-8:]\n",
    "x_test = test[['raw_acc','proc_gyro','raw_magnet','watch_acceleration','watch_heading', 'location', 'location_quick_features', 'audio_naive', 'audio_properties', 'discrete', 'lf_measurements']]\n",
    "y_test = np.asarray(test.iloc[:,-8:])\n",
    "y_test_decode = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_decode.insert(len(y_test_decode),np.argmax(y_test[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #scale features between 0 and 1\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = np.asarray(x_train).reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "x_test = np.asarray(x_test).reshape(x_test.shape[0], 1, x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "    model = Sequential()\n",
    "    #model.add(LSTM(500, input_shape=(x_train.shape[1], x_train.shape[2]), bias_regularizer=L1L2(l1=0.01, l2=0.01)))\n",
    "    model.add(LSTM(500, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dense(2000, activation='relu'))\n",
    "    model.add(Dropout(0.2, noise_shape=None, seed=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit([x_train], batch_size=20, y=y_train, verbose=1, validation_split=0.25, shuffle=True, epochs=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227768 samples, validate on 75923 samples\n",
      "Epoch 1/1\n",
      "227768/227768 [==============================] - 212s 932us/step - loss: 0.9967 - acc: 0.6384 - val_loss: 1.3501 - val_acc: 0.5357\n",
      "Saved test_models/model_1.nn\n",
      "Train on 227768 samples, validate on 75923 samples\n",
      "Epoch 1/1\n",
      "227768/227768 [==============================] - 208s 915us/step - loss: 1.0040 - acc: 0.6352 - val_loss: 1.3665 - val_acc: 0.5208\n",
      "Saved test_models/model_2.nn\n",
      "Train on 227768 samples, validate on 75923 samples\n",
      "Epoch 1/1\n",
      "227768/227768 [==============================] - 211s 925us/step - loss: 1.0027 - acc: 0.6342 - val_loss: 1.2763 - val_acc: 0.5688\n",
      "Saved test_models/model_3.nn\n"
     ]
    }
   ],
   "source": [
    "# create directory for models\n",
    "dir_name = \"test_models\"\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "# fit and save models\n",
    "n_members = 3\n",
    "for i in range(n_members):\n",
    "    # fit model\n",
    "    model = fit_model(x_train, y_train)\n",
    "    # save model\n",
    "    filename = dir_name + '/model_' + str(i + 1) + '.nn'\n",
    "    model.save(filename)\n",
    "    print('Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
